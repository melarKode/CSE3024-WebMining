{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599287753208",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(G, alpha=0.85, personalization=None, \n",
    "             max_iter=100, tol=1.0e-6, nstart=None, weight='weight', \n",
    "             dangling=None):\n",
    "    if len(G) == 0: \n",
    "        return {} \n",
    "  \n",
    "    if not G.is_directed(): \n",
    "        D = G.to_directed() \n",
    "    else: \n",
    "        D = G \n",
    "    W = nx.stochastic_graph(D, weight=weight) \n",
    "    N = W.number_of_nodes() \n",
    "  \n",
    "    if nstart is None: \n",
    "        x = dict.fromkeys(W, 1.0 / N) \n",
    "    else: \n",
    "        s = float(sum(nstart.values())) \n",
    "        x = dict((k, v / s) for k, v in nstart.items()) \n",
    "  \n",
    "    if personalization is None: \n",
    "  \n",
    "        p = dict.fromkeys(W, 1.0 / N) \n",
    "    else: \n",
    "        missing = set(G) - set(personalization) \n",
    "        if missing: \n",
    "            raise NetworkXError('Personalization dictionary '\n",
    "                                'must have a value for every node. '\n",
    "                                'Missing nodes %s' % missing) \n",
    "        s = float(sum(personalization.values())) \n",
    "        p = dict((k, v / s) for k, v in personalization.items()) \n",
    "  \n",
    "    if dangling is None: \n",
    "  \n",
    "        dangling_weights = p \n",
    "    else: \n",
    "        missing = set(G) - set(dangling) \n",
    "        if missing: \n",
    "            raise NetworkXError('Dangling node dictionary '\n",
    "                                'must have a value for every node. '\n",
    "                                'Missing nodes %s' % missing) \n",
    "        s = float(sum(dangling.values())) \n",
    "        dangling_weights = dict((k, v/s) for k, v in dangling.items()) \n",
    "    dangling_nodes = [n for n in W if W.out_degree(n, weight=weight) == 0.0] \n",
    "  \n",
    "    for _ in range(max_iter): \n",
    "        xlast = x \n",
    "        x = dict.fromkeys(xlast.keys(), 0) \n",
    "        danglesum = alpha * sum(xlast[n] for n in dangling_nodes) \n",
    "        for n in x: \n",
    "  \n",
    "            for nbr in W[n]: \n",
    "                x[nbr] += alpha * xlast[n] * W[n][nbr][weight] \n",
    "            x[n] += danglesum * dangling_weights[n] + (1.0 - alpha) * p[n] \n",
    "  \n",
    "        err = sum([abs(x[n] - xlast[n]) for n in x]) \n",
    "        if err < N*tol: \n",
    "            return x \n",
    "    raise NetworkXError('pagerank: power iteration failed to converge '\n",
    "                        'in %d iterations.' % max_iter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: 0.013170520344914423,\n 1: 0.01358092622179591,\n 2: 0.01317710857021811,\n 3: 0.012960641052663993,\n 4: 0.012163116229132225,\n 5: 0.013363337857132625,\n 6: 0.012168022013873426,\n 7: 0.013176449248507088,\n 8: 0.012768206765380118,\n 9: 0.01316178306033806,\n 10: 0.012955661220892454,\n 11: 0.0129703508723824,\n 12: 0.01296231407138459,\n 13: 0.012769603975517529,\n 14: 0.0127609753910553,\n 15: 0.01257240495947983,\n 16: 0.012769259975586153,\n 17: 0.013775961559707348,\n 18: 0.012973758274605045,\n 19: 0.01336654101367002,\n 20: 0.012776519611121967,\n 21: 0.012179029985365226,\n 22: 0.012149894469846352,\n 23: 0.013375815353839932,\n 24: 0.013176490663023167,\n 25: 0.012753713416546733,\n 26: 0.013166149084225854,\n 27: 0.012561194960376469,\n 28: 0.01236323421260676,\n 29: 0.01234108971397201,\n 30: 0.013775961559707348,\n 31: 0.012961954112093107,\n 32: 0.012977282427827795,\n 33: 0.01358092622179591,\n 34: 0.012964658174190302,\n 35: 0.01255470093972267,\n 36: 0.012990728111709518,\n 37: 0.013775961559707348,\n 38: 0.012770478545601451,\n 39: 0.01297950645998919,\n 40: 0.013152466018253362,\n 41: 0.02786240106791805,\n 42: 0.02762852227560603,\n 43: 0.027358792630489282,\n 44: 0.027011666148274792,\n 45: 0.026559560339694945,\n 46: 0.026328793107725377,\n 47: 0.02563357992119265,\n 48: 0.025532653992867634,\n 49: 0.025021676274770692,\n 50: 0.024514442545731166,\n 51: 0.024373621445844908,\n 52: 0.023844810721709773,\n 53: 0.023531599179614667,\n 54: 0.023223352899292195,\n 55: 0.02263835951554929,\n 56: 0.022766919446260147,\n 57: 0.02206410164016256,\n 58: 0.021773442730509008,\n 59: 0.021437005837027616}"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import networkx as nx\n",
    "G = nx.barabasi_albert_graph(60,41)\n",
    "pr = pagerank(G,0.4)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}